{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPj3WtUAfWnO6Eh/l5edatI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sracha4355/Character-Aware-Neural-Language-Model/blob/main/notebooks/character_aware_neural_language_refined.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QG4yqy8_YTCJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ie7BuvY8Wk2i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from spacy.tokenizer import Tokenizer\n",
        "from spacy.lang.en import English"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initalize Spacy's English tokenizer"
      ],
      "metadata": {
        "id": "bERfdbEhZLqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = English()\n",
        "tokenizer = nlp.tokenizer"
      ],
      "metadata": {
        "id": "XQZVqM09X7ni"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenize the text and extract all the unique characters"
      ],
      "metadata": {
        "id": "MP0A9clLZixm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content, train_tokens, characters = \"\", [], set()\n",
        "with open(\"wsj_train.txt\", \"r\") as file:\n",
        "  content = file.read()\n",
        "train_tokens = [token.text for token in tokenizer(content)]\n",
        "for token in train_tokens:\n",
        "  for char in token:\n",
        "    characters.add(char)"
      ],
      "metadata": {
        "id": "Eh7dWHcxZGf6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the max word length because we will zero pad words smaller than this length"
      ],
      "metadata": {
        "id": "dc1GB6PnbItY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_word_length = -1\n",
        "for index, token in enumerate(train_tokens):\n",
        "  if len(token) > max_word_length:\n",
        "    max_word_length = len(token)\n",
        "assert max_word_length == 29"
      ],
      "metadata": {
        "id": "onZAvULCZJbs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding the text and characters into integers for the model to understand"
      ],
      "metadata": {
        "id": "UL7RYUm7bvF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_int = dict((c, i) for i, c in enumerate(characters))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(characters))\n",
        "token_to_int = dict((token, i) for i, token in enumerate(train_tokens))\n",
        "int_to_token = dict((i, token) for i, token in enumerate(train_tokens))"
      ],
      "metadata": {
        "id": "lblP0zc6bs20"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sequence:\n",
        "  def __init__(self, num_batches, token_count, drop_batch=True):\n",
        "    self.num_batches = num_batches\n",
        "    if drop_batch:\n",
        "      self.token_count = token_count - (token_count % self.num_batches)\n",
        "      assert self.token_count % self.num_batches == 0\n",
        "    else:\n",
        "      self.token_count = token_count\n",
        "    self.batch_size = self.token_count // self.num_batches\n",
        "    self.current_token = 0\n",
        "\n",
        "  def __next__(self):\n",
        "    if self.current_token == self.token_count:\n",
        "      raise StopIteration\n",
        "\n",
        "    interval = [self.current_token, self.current_token + self.batch_size]\n",
        "    self.current_token += self.batch_size\n",
        "    return interval\n",
        "\n",
        "  def __iter__(self):\n",
        "    return self"
      ],
      "metadata": {
        "id": "GnV4ezuFcUuu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_tokens(tokens, int_to_token):\n",
        "  return [[int_to_token[char] for char in token] for token in tokens]\n"
      ],
      "metadata": {
        "id": "sNWQRlPhNbHK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 16"
      ],
      "metadata": {
        "id": "hpDBuN6jpWtN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# responsibility of this class is getting encoded tokens and converting them to char embeddings\n",
        "class CharEmbeddings(nn.Module):\n",
        "  def __init__(self, num_chars, embedding_dim, max_token_length, device):\n",
        "    super(CharEmbeddings, self).__init__()\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.max_token_length = max_token_length\n",
        "    self.start_of_word_idx = num_chars\n",
        "    self.end_of_word_idx = num_chars + 1\n",
        "    self.embeddings = nn.Embedding(num_chars + 2, embedding_dim)\n",
        "    self.device = device\n",
        "\n",
        "  # change this to return the transformed characters in batches\n",
        "  def forward(self, tokens):\n",
        "    batch_size = len(tokens[0])\n",
        "    batches = len(tokens)\n",
        "    embeddings = torch.zeros(batches, batch_size, self.max_token_length + 2, self.embedding_dim)\n",
        "\n",
        "    for batch in range(batches):\n",
        "      for index, token_list in enumerate(tokens[batch]):\n",
        "        character_embeddings = self.embeddings(torch.tensor([self.start_of_word_idx] + token_list + [self.end_of_word_idx], dtype=torch.long, device=self.device))\n",
        "        character_embeddings = torch.nn.functional.pad(\n",
        "            character_embeddings,\n",
        "            (0,0,0, self.max_token_length + 2 - character_embeddings.shape[0])\n",
        "        )\n",
        "        embeddings[batch][index] = character_embeddings\n",
        "    return embeddings\n",
        "\n",
        "'''ce = CharEmbeddings(len(characters), 16, max_word_length)\n",
        "encoded_tokens = [encode_tokens(train_tokens[0:2], char_to_int)]\n",
        "tensor = ce(encoded_tokens)'''"
      ],
      "metadata": {
        "id": "NrPFnH6moonv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fdbbb6ed-84e5-45bf-d2e8-9f8cc7151068"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ce = CharEmbeddings(len(characters), 16, max_word_length)\\nencoded_tokens = [encode_tokens(train_tokens[0:2], char_to_int)]\\ntensor = ce(encoded_tokens)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bli3VteRuo5N"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SMALL = [(w, 25 * w) for w in range(1, 7)]\n",
        "LARGE = [(w, min(200, w * 50)) for w in range(1, 8)]\n",
        "\n",
        "\n",
        "class CharCNN(nn.Module):\n",
        "  def __init__(self, embedding_dim, activation, filter_width_mapping):\n",
        "    super().__init__()\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.activation = activation\n",
        "    self.conv_layers = nn.ModuleList()\n",
        "    self.total_num_filters = 0\n",
        "    # filter_width_mapping is a set of tuples\n",
        "    # (int, int)\n",
        "    for width, num_filters in filter_width_mapping:\n",
        "      self.conv_layers.append(\n",
        "          nn.Conv2d (\n",
        "            in_channels=1,\n",
        "            out_channels =num_filters,\n",
        "            kernel_size=(width, self.embedding_dim),\n",
        "            padding=0,\n",
        "            stride=1,\n",
        "            bias=True\n",
        "        )\n",
        "      )\n",
        "      self.total_num_filters += num_filters\n",
        "\n",
        "  def forward(self, tokens):\n",
        "    max_over_time_poolings = torch.zeros(tokens.shape[0], self.total_num_filters)\n",
        "    convolution_results = []\n",
        "    for conv_layer in self.conv_layers:\n",
        "      x = conv_layer(tokens)\n",
        "      x = torch.squeeze(x, dim=3)\n",
        "      x = self.activation(x)\n",
        "      max_over_time, _ = torch.max(x, dim=2, keepdim=False)\n",
        "      convolution_results.append(max_over_time)\n",
        "    x = torch.cat(convolution_results,dim=1)\n",
        "    return x"
      ],
      "metadata": {
        "id": "MPu-HNvdPQwL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LGP9kC6gQQxu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HighwayNetwork(nn.Module):\n",
        "  def __init__(self, layers, activation, input_size):\n",
        "    super().__init__()\n",
        "    self.activation = activation\n",
        "    self.layers = layers\n",
        "    # z = t  g(WHy + bH) + (1 − t) y\n",
        "    self.highway_matrices = nn.ModuleList([\n",
        "        nn.Linear(input_size, input_size, bias=True)\n",
        "        for _ in range(layers * 2)\n",
        "    ])\n",
        "\n",
        "  def _highway_layers(self, y):\n",
        "    z = y\n",
        "    for i in range(self.layers):\n",
        "      highway_gate, transform_gate = self.highway_matrices[i * 2], self.highway_matrices[i * 2 + 1]\n",
        "      t = F.sigmoid(transform_gate(z))\n",
        "      z = t * self.activation(highway_gate(z)) + (1 - t) * z\n",
        "    return z\n",
        "\n",
        "  def forward(self, tokens):\n",
        "    batches = tokens.shape[0]\n",
        "    for batch in range(batches):\n",
        "      tensor = tokens[batch]\n",
        "      for i in range(len(tensor)):\n",
        "        row_view = tensor[i]\n",
        "        row_view = torch.unsqueeze(row_view, dim=0)\n",
        "        row_view = self._highway_layers(row_view)\n",
        "        tensor[i] = torch.squeeze(row_view, dim=0)\n",
        "    return tokens\n",
        "\n",
        "class character_aware_nlm(nn.Module):\n",
        "  def __init__(\n",
        "      self,\n",
        "      Sequencer,\n",
        "      max_token_length,\n",
        "      embedding_dim,\n",
        "      num_characters,\n",
        "      activation,\n",
        "      filter_width_mapping,\n",
        "      batch_size,\n",
        "      num_highway_layers,\n",
        "      highway_activation,\n",
        "      num_rnn_layers,\n",
        "      rnn_hidden_units,\n",
        "      vocab_size,\n",
        "      device\n",
        "    ):\n",
        "    super().__init__()\n",
        "    self.sequencer = Sequencer # get the intervals for the batching the dataset\n",
        "    self.CharEmbeddingModule = CharEmbeddings(num_characters, embedding_dim, max_token_length, device)\n",
        "    self.CharCNNModule = CharCNN(embedding_dim, activation, filter_width_mapping).to(device)\n",
        "    self.HighwayNetworkModule = HighwayNetwork(num_highway_layers, highway_activation, self.CharCNNModule.total_num_filters).to(device)\n",
        "    self.lstm = nn.LSTM(\n",
        "        input_size=self.CharCNNModule.total_num_filters,\n",
        "        num_layers=num_rnn_layers,\n",
        "        hidden_size=rnn_hidden_units,\n",
        "        batch_first=True\n",
        "      ).to(device)\n",
        "    self.word_prediction_layer = nn.Linear(rnn_hidden_units, vocab_size).to(device)\n",
        "\n",
        "  def forward(self, tokens):\n",
        "    batches = len(tokens)\n",
        "    batch_size = len(tokens[0])\n",
        "    # get the character embeddings\n",
        "    character_embeddings = self.CharEmbeddingModule(tokens)\n",
        "\n",
        "    # feed them to the CNN and store the max over time output of each filter\n",
        "    cnn_output = torch.zeros(batches, batch_size, self.CharCNNModule.total_num_filters).to(device)\n",
        "    for batch in range(character_embeddings.shape[0]):\n",
        "      tensor = torch.unsqueeze(character_embeddings[batch], dim=1).to(device)\n",
        "      print('in batch loop', batch ,tensor.device)\n",
        "      cnn_output[batch] = self.CharCNNModule(tensor)\n",
        "\n",
        "    # pass CNN's out to highway network\n",
        "    highway_output = self.HighwayNetworkModule(cnn_output)\n",
        "    return self.lstm_forward(highway_output)\n",
        "\n",
        "  def lstm_forward(self, input):\n",
        "    print('in lstm_forward', input.shape)\n",
        "    initial_hidden_state = torch.zeros(self.lstm.num_layers, input.size(0), self.lstm.hidden_size).to(device)\n",
        "    initial_memory_cell = torch.zeros(self.lstm.num_layers, input.size(0), self.lstm.hidden_size).to(device)\n",
        "    out, _ = self.lstm(input, (initial_hidden_state, initial_memory_cell))\n",
        "    print('out is on device', out.device)\n",
        "    out = out[:, -1, :]\n",
        "    print(out.shape)\n",
        "    predicted_word = self.word_prediction_layer(out)\n",
        "    return predicted_word\n",
        "\n",
        "  def predict(self, training_data):\n",
        "    logits = self.forward(training_data)\n",
        "    logits = F.softmax(logits, dim=1)\n",
        "    logits = torch.flatten(logits)\n",
        "    max_logit, prediction_index = torch.max(logits, dim=0)\n",
        "    return prediction_index\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size_test = 4\n",
        "print('number of tokens', len(train_tokens))\n",
        "print('number of unique tokens', len(token_to_int))\n",
        "model = character_aware_nlm(\n",
        "    None,\n",
        "    max_word_length,\n",
        "    EMBEDDING_DIM,\n",
        "    len(characters),\n",
        "    F.tanh,\n",
        "    SMALL,\n",
        "    batch_size_test,\n",
        "    2,\n",
        "    F.relu,\n",
        "    2,\n",
        "    300,\n",
        "    len(token_to_int),\n",
        "    device\n",
        ")\n",
        "model.to(device)\n",
        "encoded_tokens = [encode_tokens(train_tokens, char_to_int)]\n",
        "predicted_word = model.predict(encoded_tokens)\n",
        "print(int_to_token[predicted_word.item()])\n"
      ],
      "metadata": {
        "id": "WJVgi6eRJ50j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ac19b5b0-e312-424a-eedb-66fcdb9130fd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of tokens 1078473\n",
            "number of unique tokens 41586\n",
            "in batch loop 0 cuda:0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 6.03 GiB. GPU 0 has a total capacity of 14.75 GiB of which 2.67 GiB is free. Process 10679 has 12.08 GiB memory in use. Of the allocated memory 8.92 GiB is allocated by PyTorch, and 3.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-2c1e3b1ed1a4>\u001b[0m in \u001b[0;36m<cell line: 118>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0mencoded_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mencode_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_to_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m \u001b[0mpredicted_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_to_token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted_word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-2c1e3b1ed1a4>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, training_data)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-2c1e3b1ed1a4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     70\u001b[0m       \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcharacter_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'in batch loop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m       \u001b[0mcnn_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCharCNNModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# pass CNN's out to highway network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-724af4f9dd85>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mconvolution_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mconv_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 6.03 GiB. GPU 0 has a total capacity of 14.75 GiB of which 2.67 GiB is free. Process 10679 has 12.08 GiB memory in use. Of the allocated memory 8.92 GiB is allocated by PyTorch, and 3.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iYRe-rG_yxNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2SoU9SRIZHgP"
      }
    }
  ]
}