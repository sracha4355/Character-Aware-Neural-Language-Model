{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of the notebook is the exact same as haracter_aware_neural_language_final.ipynb except the dataloader class is different. Please refer to the comments there. Note, some filepaths might need to be changed for code to work.\n",
    "\n",
    "### the outputs in the notebook are not accurate, as in the late stages I moved the notebook to ADA cluster, and trained my models there. The real results are in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QG4yqy8_YTCJ",
    "outputId": "1e87115e-836d-4a9f-c9fb-ac4deef75604"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: torchviz in /usr/local/lib/python3.10/dist-packages (0.0.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.5.1+cu121)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (3.0.2)\n",
      "Collecting conllu\n",
      "  Downloading conllu-6.0.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading conllu-6.0.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: conllu\n",
      "Successfully installed conllu-6.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchviz\n",
    "!pip install conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "Ie7BuvY8Wk2i"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "from torch.utils.data import DataLoader\n",
    "from conllu import parse\n",
    "import collections\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "from torchviz import make_dot\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dbGmjEwVqByt"
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_filepath, model, optimizer):\n",
    "  checkpoint = torch.load(checkpoint_filepath)\n",
    "  model.load_state_dict(checkpoint['model_state_dict'])\n",
    "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "  epoch = checkpoint['epoch']\n",
    "  loss = checkpoint['loss']\n",
    "  print(f'Checkpoint loaded from {checkpoint_filepath} starting at epoch: {epoch}, current_loss: {loss}')\n",
    "  return epoch, loss\n",
    "\n",
    "def save_checkpoint(epoch, loss, model, optimizer, checkpoint_filepath):\n",
    "  torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss\n",
    "  }, checkpoint_filepath)\n",
    "\n",
    "def delete_checkpoint_files():\n",
    "  regex = re.compile(r\"^checkpoint.*\")\n",
    "  for filename in os.listdir('./'):\n",
    "    if regex.match(filename):\n",
    "      try:\n",
    "        os.remove(filename)\n",
    "        print(f'deleted {filename}')\n",
    "      except OSError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "F_Oo9SCDUHCy"
   },
   "outputs": [],
   "source": [
    "class UDTeluguDataloader(Dataset):\n",
    "  def __init__(\n",
    "      self,\n",
    "      split=\"train\",\n",
    "      directory_path=\"\",\n",
    "      batch_size=20\n",
    "    ):\n",
    "\n",
    "    self.characters = []\n",
    "    self.tokens = []\n",
    "    self.splits = {}\n",
    "    self.split = split\n",
    "    self.batch_size = batch_size\n",
    "\n",
    "    # create mappings for each character and token type\n",
    "    self.char_to_int = {}\n",
    "    self.token_to_int = {}\n",
    "    self.int_to_char = {}\n",
    "    self.int_to_token = {}\n",
    "\n",
    "    for split in [\"dev\", \"test\", \"train\"]:\n",
    "      file = f'{directory_path}te_mtg-ud-{split}.conllu'\n",
    "      content = \"\"\n",
    "      with open(file, \"r\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "      sentences = parse(content)\n",
    "      for token_list in sentences:\n",
    "        for token in token_list:\n",
    "          #print(token['form'])\n",
    "          self.tokens.append(token['form'])\n",
    "          for char in token['form']:\n",
    "            self.characters.append(char)\n",
    "\n",
    "    # populate the encoding mappings\n",
    "    self.tokens = set(sorted(self.tokens))\n",
    "    self.characters = set(sorted(self.characters))\n",
    "    for i, token in enumerate(self.tokens):\n",
    "      self.token_to_int[token] = i\n",
    "      self.int_to_token[i] = token\n",
    "\n",
    "    for i, character in enumerate(self.characters):\n",
    "      self.char_to_int[character] = i\n",
    "      self.int_to_char[i] = character\n",
    "\n",
    "    assert len(self.char_to_int) == len(self.int_to_char)\n",
    "    assert len(self.token_to_int) == len(self.int_to_token)\n",
    "    assert len(self.char_to_int) == len(self.characters)\n",
    "    assert len(self.token_to_int) == len(self.tokens)\n",
    "\n",
    "    for split in [\"dev\", \"test\", \"train\"]:\n",
    "      file = f'{directory_path}te_mtg-ud-{split}.conllu'\n",
    "      content = \"\"\n",
    "      with open(file, \"r\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "      # encode the tokens\n",
    "      encoded_tokens = []\n",
    "      sentences = parse(content)\n",
    "      for token_list in sentences:\n",
    "        for token in token_list:\n",
    "          encoded_tokens.append([])\n",
    "          for char in token['form']:\n",
    "            #print('ll', char)\n",
    "            encoded_tokens[-1].append(\n",
    "                self.char_to_int[char]\n",
    "            )\n",
    "      self.splits[split] = encoded_tokens\n",
    "\n",
    "  def __len__(self):\n",
    "    return ((len(self.splits[self.split]) - 1) // self.batch_size)\n",
    "\n",
    "  def __getitem__(self, index, as_tensor=False):\n",
    "    if index == self.__len__():\n",
    "      raise IndexError(f'Provide an index between 0 and {self.__len__() + 1}')\n",
    "\n",
    "    cutoff = self.__len__() * self.batch_size\n",
    "    token = self.splits\\\n",
    "     [self.split]\\\n",
    "     [index * self.batch_size : min(index * self.batch_size + self.batch_size, cutoff)]\n",
    "\n",
    "    prediction = self.splits[self.split][min(index * self.batch_size + self.batch_size, cutoff)]\n",
    "\n",
    "    characters = []\n",
    "    for character in prediction:\n",
    "      characters.append(self.int_to_char[character])\n",
    "    prediction = self.token_to_int[\"\".join(characters)]\n",
    "\n",
    "    if as_tensor:\n",
    "      return torch.tensor(token), torch.tensor(prediction)\n",
    "    return token, prediction\n",
    "\n",
    "  def change_split(self, split):\n",
    "    if split != \"dev\" and split != \"train\" and split != \"test\":\n",
    "        raise ValueError(\"Provide a valid split. Options are dev, test, train.\")\n",
    "    self.split = split\n",
    "    return self\n",
    "\n",
    "  def get_encoding_mappings(self):\n",
    "    return self.char_to_int, self.int_to_char, self.token_to_int, self.int_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "hpDBuN6jpWtN"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "MPu-HNvdPQwL"
   },
   "outputs": [],
   "source": [
    "SMALL = [(w, 25 * w) for w in range(1, 7)]\n",
    "LARGE = [(w, min(200, w * 50)) for w in range(1, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJVgi6eRJ50j"
   },
   "outputs": [],
   "source": [
    "\n",
    "# responsibility of this class is getting encoded tokens and converting them to char embeddings\n",
    "class CharEmbeddings(nn.Module):\n",
    "  def __init__(self, num_chars, embedding_dim, max_token_length, device):\n",
    "    super(CharEmbeddings, self).__init__()\n",
    "    self.embedding_dim = embedding_dim\n",
    "    self.max_token_length = max_token_length\n",
    "    self.start_of_word_idx = num_chars\n",
    "    self.end_of_word_idx = num_chars + 1\n",
    "    self.device = device\n",
    "    self.embeddings = nn.Embedding(num_chars + 2, embedding_dim).to(self.device)\n",
    "\n",
    "\n",
    "  # change this to return the transformed characters in batches\n",
    "  def forward(self, tokens):\n",
    "    batch_size = len(tokens[0])\n",
    "    batches = len(tokens)\n",
    "\n",
    "    _embeddings = []\n",
    "\n",
    "    for batch in range(batches):\n",
    "      embeddings_for_batch = []\n",
    "      for index, token_list in enumerate(tokens[batch]):\n",
    "        character_embeddings = self.embeddings(torch.tensor([self.start_of_word_idx] + token_list + [self.end_of_word_idx], dtype=torch.long, device=self.device))\n",
    "        character_embeddings = torch.nn.functional.pad(\n",
    "            character_embeddings,\n",
    "            (0,0,0, self.max_token_length + 2 - character_embeddings.shape[0])\n",
    "        )\n",
    "\n",
    "        embeddings_for_batch.append(character_embeddings)\n",
    "\n",
    "\n",
    "      _embeddings.append(\n",
    "          torch.stack(embeddings_for_batch, dim=0)\n",
    "      )\n",
    "\n",
    "    tensor = torch.stack(\n",
    "        _embeddings, dim=0\n",
    "    )\n",
    "\n",
    "    return tensor\n",
    "\n",
    "\n",
    "class CharCNN(nn.Module):\n",
    "  def __init__(self, embedding_dim, activation, filter_width_mapping, device):\n",
    "    super().__init__()\n",
    "    self.embedding_dim = embedding_dim\n",
    "    self.activation = activation\n",
    "    self.conv_layers = nn.ModuleList()\n",
    "    self.total_num_filters = 0\n",
    "    self.device = device\n",
    "\n",
    "    # filter_width_mapping is a set of tuples\n",
    "    # (int, int)\n",
    "    for width, num_filters in filter_width_mapping:\n",
    "      self.conv_layers.append(\n",
    "          nn.Conv2d (\n",
    "            in_channels=1,\n",
    "            out_channels =num_filters,\n",
    "            kernel_size=(width, self.embedding_dim),\n",
    "            padding=0,\n",
    "            stride=1,\n",
    "            bias=True\n",
    "        ).to(self.device)\n",
    "      )\n",
    "      self.total_num_filters += num_filters\n",
    "\n",
    "  def forward(self, tokens):\n",
    "    tokens = tokens.to(self.device)\n",
    "    convolution_results = []\n",
    "\n",
    "    for conv_layer in self.conv_layers:\n",
    "      x = conv_layer(tokens)\n",
    "      x = torch.squeeze(x, dim=3)\n",
    "      x = self.activation(x)\n",
    "      max_over_time, _ = torch.max(x, dim=2, keepdim=False)\n",
    "      convolution_results.append(max_over_time)\n",
    "\n",
    "    x = torch.cat(convolution_results,dim=1)\n",
    "\n",
    "    return x\n",
    "\n",
    "class HighwayNetwork(nn.Module):\n",
    "  def __init__(self, layers, activation, input_size, device):\n",
    "    super().__init__()\n",
    "    self.activation = activation\n",
    "    self.layers = layers\n",
    "    self.device = device\n",
    "\n",
    "    self.highway_matrices = nn.ModuleList([\n",
    "        nn.Linear(input_size, input_size, bias=True).to(device)\n",
    "        for _ in range(layers * 2)\n",
    "    ])\n",
    "\n",
    "  def _highway_layers(self, y):\n",
    "    z = y\n",
    "    for i in range(self.layers):\n",
    "      highway_gate, transform_gate = self.highway_matrices[i * 2], self.highway_matrices[i * 2 + 1]\n",
    "      t = F.sigmoid(transform_gate(z))\n",
    "      z = t * self.activation(highway_gate(z)) + (1 - t) * z\n",
    "    return z\n",
    "\n",
    "  def forward(self, tokens):\n",
    "    shape = tokens.shape\n",
    "    tokens = torch.reshape(tokens, (tokens.shape[1], tokens.shape[2]))\n",
    "    highway_output = []\n",
    "    for row in tokens:\n",
    "      row = torch.unsqueeze(row, dim=0)\n",
    "      highway_output.append(self._highway_layers(row))\n",
    "\n",
    "    highway_output = torch.stack(highway_output, dim=0).reshape(shape)\n",
    "    return highway_output\n",
    "\n",
    "class character_aware_nlm(nn.Module):\n",
    "  def __init__(\n",
    "      self,\n",
    "      max_token_length,\n",
    "      embedding_dim,\n",
    "      num_characters,\n",
    "      activation,\n",
    "      filter_width_mapping,\n",
    "      batch_size,\n",
    "      num_highway_layers,\n",
    "      highway_activation,\n",
    "      num_rnn_layers,\n",
    "      rnn_hidden_units,\n",
    "      vocab_size,\n",
    "      device,\n",
    "      dropout=0.5,\n",
    "      output_layer_dropout=0.5\n",
    "    ):\n",
    "    super().__init__()\n",
    "    self.CharEmbeddingModule = CharEmbeddings(num_characters, embedding_dim, max_token_length, device)\n",
    "    self.CharCNNModule = CharCNN(embedding_dim, activation, filter_width_mapping, device)\n",
    "    self.HighwayNetworkModule = HighwayNetwork(num_highway_layers, highway_activation, self.CharCNNModule.total_num_filters, device)\n",
    "    self.lstm = nn.LSTM(\n",
    "        input_size=self.CharCNNModule.total_num_filters,\n",
    "        num_layers=num_rnn_layers,\n",
    "        hidden_size=rnn_hidden_units,\n",
    "        batch_first=True,\n",
    "        dropout=dropout\n",
    "      ).to(device)\n",
    "    self.word_prediction_layer = nn.Linear(rnn_hidden_units, vocab_size).to(device)\n",
    "    self.prediction_layer_dropout = nn.Dropout(output_layer_dropout)\n",
    "    self.device = device\n",
    "\n",
    "  def forward(self, tokens):\n",
    "    batches = len(tokens)\n",
    "    batch_size = len(tokens[0])\n",
    "    character_embeddings = self.CharEmbeddingModule(tokens)\n",
    "\n",
    "    output = []\n",
    "    for batch in range(character_embeddings.shape[0]):\n",
    "      tensor = torch.unsqueeze(character_embeddings[batch], dim=1).to(self.device)\n",
    "      output.append(self.CharCNNModule(tensor))\n",
    "    output = torch.stack(output, dim=0)\n",
    "    highway_output = self.HighwayNetworkModule(output)\n",
    "    return self.lstm_forward(highway_output)\n",
    "\n",
    "  def lstm_forward(self, input):\n",
    "\n",
    "    out, (hidden, cell) = self.lstm(input)\n",
    "    out = out[:, out.shape[1] - 1:out.shape[1], :].reshape(out.shape[0], -1)\n",
    "    out = self.prediction_layer_dropout(out)\n",
    "    return self.word_prediction_layer(out)\n",
    "\n",
    "  def predict(self, training_data, get_logits=False):\n",
    "    logits = self.forward(training_data)\n",
    "    if get_logits:\n",
    "      return logits\n",
    "\n",
    "    logits = F.softmax(logits, dim=1)\n",
    "    logits = torch.flatten(logits)\n",
    "    max_logit, prediction_index = torch.max(logits, dim=0)\n",
    "    return prediction_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "2E8-LMPGCC6a"
   },
   "outputs": [],
   "source": [
    "training_data = UDTeluguDataloader(split=\"train\")\n",
    "dev_data = UDTeluguDataloader(split=\"dev\")\n",
    "test_data = UDTeluguDataloader(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "9C7ZqdOeDoOs"
   },
   "outputs": [],
   "source": [
    "SMALL = [(w, 25 * w) for w in range(1, 7)]\n",
    "LARGE = [(w, min(200, w * 50)) for w in range(1, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "r953GWK-dI0C"
   },
   "outputs": [],
   "source": [
    "USE_CHECKPOINT = False\n",
    "CHECKPOINT_FILEPATH = \"checkpoint.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "vkoWJjJsle5p"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "         for index, tokens_and_prediction in enumerate(dataloader):\n",
    "            tokens, prediction = tokens_and_prediction\n",
    "            prediction = torch.tensor([prediction], dtype=torch.long, device=device)\n",
    "            logits = model([tokens])\n",
    "            loss = loss_fn(logits, prediction)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_tokens += prediction.numel()\n",
    "\n",
    "    avg_nll = total_loss / total_tokens\n",
    "    perplexity = math.exp(avg_nll)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "oUNJfY03SShz"
   },
   "outputs": [],
   "source": [
    "max_word_length = -1\n",
    "for word in training_data.tokens:\n",
    "    max_word_length = max(len(word), max_word_length)\n",
    "\n",
    "model_args = {\n",
    "      \"max_token_length\": max_word_length,\n",
    "      \"embedding_dim\": 15,\n",
    "      \"num_characters\": len(training_data.characters),\n",
    "      \"activation\": F.tanh,\n",
    "      \"filter_width_mapping\": SMALL,\n",
    "      \"batch_size\": 20,\n",
    "      \"num_highway_layers\": 1,\n",
    "      \"highway_activation\": F.relu,\n",
    "      \"num_rnn_layers\": 2,\n",
    "      \"rnn_hidden_units\": 300,\n",
    "      \"vocab_size\": len(training_data.tokens),\n",
    "      \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "      \"dropout\": 0,\n",
    "      \"output_layer_dropout\":0.5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "ajSHjS8MLw8I"
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    optim,\n",
    "    model_args,\n",
    "    train_dataloader,\n",
    "    dev_dataloader,\n",
    "    _batch_size=20,\n",
    "    _epochs=25,\n",
    "    checkpoint=None\n",
    "):\n",
    "\n",
    "  EPOCHS = _epochs\n",
    "  BATCH_SIZE = _batch_size\n",
    "  LEARNING_RATE = 1\n",
    "\n",
    "  train_dataloader.batch_size = BATCH_SIZE\n",
    "  dev_dataloader.batch_size = BATCH_SIZE\n",
    "\n",
    "  max_word_length = -1\n",
    "  for word in train_dataloader.tokens:\n",
    "    max_word_length = max(len(word), max_word_length)\n",
    "\n",
    "  loss_fn = torch.nn.CrossEntropyLoss()\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  model = None\n",
    "  start_epoch = 0\n",
    "  loss = 0\n",
    "\n",
    "  if checkpoint == None:\n",
    "    model = character_aware_nlm(\n",
    "        **model_args\n",
    "    )\n",
    "    optim = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "  else:\n",
    "    # load from the check point\n",
    "    start_epoch, loss = load_checkpoint(CHECKPOINT_FILEPATH, model, optim)\n",
    "\n",
    "  for name, param in model.named_parameters():\n",
    "    if 'weight' in name:\n",
    "      nn.init.uniform_(param, -0.05, 0.05)\n",
    "    elif 'bias' in name:\n",
    "      nn.init.constant_(param, 0)\n",
    "\n",
    "  ppl = None\n",
    "  dataloader = DataLoader(train_dataloader, batch_size=2, shuffle=True)\n",
    "  for epoch in range(start_epoch, EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for index, tokens_and_prediction in enumerate(train_dataloader):\n",
    "      tokens, prediction = tokens_and_prediction\n",
    "\n",
    "      prediction = torch.tensor([prediction], dtype=torch.long, device=device)\n",
    "      optim.zero_grad()\n",
    "      logits = model([tokens])\n",
    "\n",
    "      loss = loss_fn(logits, prediction)\n",
    "      total_loss += loss.item()\n",
    "\n",
    "      # Clear gradients\n",
    "\n",
    "      loss.backward()\n",
    "\n",
    "      # Clip gradients\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "      optim.step()\n",
    "\n",
    "    new_ppl = evaluate_model(model, dev_dataloader)\n",
    "    print(f'Epoch: {epoch + 1}, Loss: {total_loss} dev PPL this epoch: {new_ppl} Time taken to finish epoch: {time.time() - start_time}')\n",
    "\n",
    "    # calculate perplexity\n",
    "    if ppl == None:\n",
    "      ppl = new_ppl\n",
    "    else:\n",
    "      if abs(new_ppl - ppl) <= 1.0:  # If perplexity improvement <= 1.0\n",
    "        for param_group in optim.param_groups:\n",
    "              param_group['lr'] /= 2  # Halve the learning rate\n",
    "              param_group['lr'] = max(param_group['lr'], 0.1) # do not deep below 0.01\n",
    "        print(f\"Learning rate halved. New LR: {optim.param_groups[0]['lr']}\")\n",
    "      ppl = new_ppl\n",
    "\n",
    "  return model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "FN9q2TCM6cR0"
   },
   "outputs": [],
   "source": [
    "small_model_before_training = character_aware_nlm(\n",
    "    **model_args\n",
    ")\n",
    "ppl_before_training = evaluate_model(small_model_before_training, test_data)\n",
    "ppl_before_training_dev = evaluate_model(small_model_before_training, dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_w5N2iR86oqm",
    "outputId": "e2e44a8c-a8f9-422a-b473-4f766bb95ec4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl on test set before training: 2085.6798785580813\n",
      "ppl on dev set before training: 2079.1527925892347\n"
     ]
    }
   ],
   "source": [
    "print(f'ppl on test set before training: {ppl_before_training}')\n",
    "print(f'ppl on dev set before training: {ppl_before_training_dev}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kd2X96QM7253",
    "outputId": "25fa6f87-d330-4c4c-9551-08694eb040d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 281.81491565704346 dev PPL this epoch: 7128.342785388419 Time taken to finish epoch: 0.9041824340820312\n",
      "Epoch: 2, Loss: 263.500155210495 dev PPL this epoch: 87812.6960137668 Time taken to finish epoch: 1.0163254737854004\n",
      "Epoch: 3, Loss: 229.7461884021759 dev PPL this epoch: 2299.3722348786832 Time taken to finish epoch: 0.8974344730377197\n",
      "Epoch: 4, Loss: 195.1967749595642 dev PPL this epoch: 2316.9693568477383 Time taken to finish epoch: 0.9008300304412842\n",
      "Epoch: 5, Loss: 175.7684302330017 dev PPL this epoch: 1449.1177301886623 Time taken to finish epoch: 1.2012977600097656\n",
      "Epoch: 6, Loss: 194.77435421943665 dev PPL this epoch: 4138.018744651627 Time taken to finish epoch: 1.3633744716644287\n",
      "Epoch: 7, Loss: 179.57392954826355 dev PPL this epoch: 1569.9106566188568 Time taken to finish epoch: 1.023893117904663\n",
      "Epoch: 8, Loss: 161.56140446662903 dev PPL this epoch: 2303.961562314085 Time taken to finish epoch: 0.9003787040710449\n",
      "Epoch: 9, Loss: 161.3192822933197 dev PPL this epoch: 2928.3681853180537 Time taken to finish epoch: 0.9136579036712646\n",
      "Epoch: 10, Loss: 155.47955775260925 dev PPL this epoch: 3108.1322503718757 Time taken to finish epoch: 0.9010682106018066\n",
      "Epoch: 11, Loss: 154.09155082702637 dev PPL this epoch: 2510.7337496394703 Time taken to finish epoch: 0.9129362106323242\n",
      "Epoch: 12, Loss: 151.09207355976105 dev PPL this epoch: 2777.447932035801 Time taken to finish epoch: 0.9042999744415283\n",
      "Epoch: 13, Loss: 150.38765788078308 dev PPL this epoch: 2628.9439373358837 Time taken to finish epoch: 0.9062914848327637\n",
      "Epoch: 14, Loss: 149.97998905181885 dev PPL this epoch: 2878.893136999218 Time taken to finish epoch: 0.8925502300262451\n",
      "Epoch: 15, Loss: 149.02664279937744 dev PPL this epoch: 2945.451238303788 Time taken to finish epoch: 0.9014244079589844\n",
      "Epoch: 16, Loss: 147.82836961746216 dev PPL this epoch: 3601.939277945164 Time taken to finish epoch: 0.8942320346832275\n",
      "Epoch: 17, Loss: 148.26180386543274 dev PPL this epoch: 3425.3450976899912 Time taken to finish epoch: 0.9180066585540771\n",
      "Epoch: 18, Loss: 143.81626510620117 dev PPL this epoch: 3783.8218049866587 Time taken to finish epoch: 1.1517553329467773\n",
      "Epoch: 19, Loss: 146.50589156150818 dev PPL this epoch: 3651.126225432457 Time taken to finish epoch: 1.3450891971588135\n",
      "Epoch: 20, Loss: 145.8317310810089 dev PPL this epoch: 3761.9594430926813 Time taken to finish epoch: 1.0491957664489746\n",
      "Epoch: 21, Loss: 146.50927114486694 dev PPL this epoch: 3681.257320798322 Time taken to finish epoch: 0.8988032341003418\n",
      "Epoch: 22, Loss: 145.5066213607788 dev PPL this epoch: 3646.8934392795536 Time taken to finish epoch: 0.9562969207763672\n",
      "Epoch: 23, Loss: 143.7452085018158 dev PPL this epoch: 4085.421064296286 Time taken to finish epoch: 0.9388673305511475\n",
      "Epoch: 24, Loss: 144.74352145195007 dev PPL this epoch: 4115.670250709431 Time taken to finish epoch: 0.9068801403045654\n",
      "Epoch: 25, Loss: 142.77566146850586 dev PPL this epoch: 4429.890858707864 Time taken to finish epoch: 0.9034502506256104\n"
     ]
    }
   ],
   "source": [
    "params_state_dict = train_model(optim=None, model_args=model_args, train_dataloader=test_data, dev_dataloader=dev_data, checkpoint=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uOps0gRC9sca",
    "outputId": "d2be7005-e5ac-4b45-def0-f9d0f109892f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model = character_aware_nlm(\n",
    "    **model_args\n",
    ")\n",
    "trained_model.load_state_dict(params_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "AVkOT9QTj2bs"
   },
   "outputs": [],
   "source": [
    "ppl_on_test_data = evaluate_model(trained_model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sue3FkFrj92V",
    "outputId": "e0373261-3c93-4718-f1f1-36b097c808cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl on test data 34.44325419862871\n"
     ]
    }
   ],
   "source": [
    "print('ppl on test data', ppl_on_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfmMj1rDkaKi"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note the outputs in the notebook are not accurate, as in the late stages I moved the notebook to ADA cluster, and trained my models there. The real results are in the report."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
